---
title: "Assignment 1"
author: "Max"
format: html
editor: visual
---

## Questions and Tasks

1.  To begin, I opened a new version controlled project with Rstudio, choosing the Git option to clone the repository given in the assignment document. After that, I added packages to the project library and check / set working directory if needed.

```{r}
#library in package, packages are already installed
library(tidyverse)
library(dplyr)
library(haven)
getwd() #check working directory, it is set to assignment folder I created using point and click GIT/ project wizard, so don't need to change using setwd()

#copied url from igor's github and cloned to create new version controlled projecton personal github
```

Now that the repository is available, I import the data and inspect for missing and unusual values. To inspect the data I first use the head function, and the view function to look at the entire data set.

```{r}
Avengers_data <- read.csv("avengers.csv")
head(Avengers_data)
view(Avengers_data)

```

2.  Now, to look at complete clean cases and create a subset with only these complete cases , will inspect for missing values and drop any rows with missing values.

    ```{r}
    clean_avengers <- drop_na(Avengers_data) #creating new object where rows with missing values are dropped using drop_na function in tidyverse
    view(clean_avengers) # new object looks as it should, missing values dropped. 


    #using drop_na is a bit of a blunt tool. it works for this data set but using na.rm in calculations would also ensure missing values aren't used in analyses, while keeping rows which may only have values missing for a few variables, but still have valuable usuable data in other vars. 
    ```

Next, the variable combat effectiveness is calculated as the sum of agility, speed, strength, and willpower

```{r}
avengers_effectiveness <- mutate(clean_avengers,combateffectiveness = (agility+ speed +strength+ willpower)) # creating a new object that includes the calculated variable combateffectiveness
head(avengers_effectiveness) #checking first rows to ensure variable was calculated and appears in data. 


```

3.  Creating dataset that only includes dead avengers with no superpowers in both spss and csv format.

```{r}
dead_avengers <- filter (avengers_effectiveness,superpower =="no" & died =="yes") #filter for avengers who have dead = yes and superpower =no 
head(dead_avengers) #check data to confirm filter worked

#write csv of new dataset
write.csv(dead_avengers, "dead_avengers.csv")

#write Sav (spss) using write_sav, part of haven package
write_sav(dead_avengers,"dead_avengers.sav")
```

Now for summary statistics

```{r}
summarise(dead_avengers, #summraise 3 vars - combateffectiveness, kills, injuries,  ,
          mean(combateffectiveness),
          mean (kills),
          mean(injuries), #calc mean for three variables
          sd(combateffectiveness),
          sd(kills),
          sd(injuries),
          min(combateffectiveness), max(combateffectiveness),
          min(kills), max(kills),
          min(injuries), max(injuries)) # min max / range for 3 var

#I don't need to use na.rm as I already dropped all cases with any missing values

summarise( #summraise 3 vars - combateffectiveness, kills, injuries, by battlefield (north/south)
  group_by(dead_avengers,north_south),# group summary stats by battlefield
          mean(combateffectiveness),
          mean (kills),
          mean(injuries), #calc mean for three variables
          sd(combateffectiveness),
          sd(kills),
          sd(injuries),
          min(combateffectiveness), max(combateffectiveness),
          min(kills), max(kills),
          min(injuries), max(injuries)) # min max / range for 3 var
          

```

4.  The north battlefield was more effective with a mean CE of 499.78. The north battlefield also had the most injuries with a mean of 4.6 compared to 4.2.

5.  The most erroneous variable -

    ```{r}
    #calculate standard error
    summarise(dead_avengers,
              sd(combateffectiveness), seCE = sd(combateffectiveness)/sqrt(101),
              sd(kills), seK = sd(kills)/sqrt(101),
              sd(injuries), seI = sd(injuries)/sqrt(101))

    ```

6.  How to estimate sample size. This will be answered in assignment write up.

```         
-   Essentially, you can conduct a power analysis, or use another method such as relying on heuristics, prior research, / just not justifying for exploratory research.
```

7.  Med effect size of 0.5, if this were a real study you could base this off effect sizes from meta analyses etc.

8.  Carry out a power analysis for chosen effect size.

    ```{r}
    library(pwr) #pwr package in library
    # code for conducting power analysis for a t test
    pwr.t.test(d= 0.5, sig.level = 0.05, power = 0.8) 

    ```

<!-- -->

9.  Determine power if there is truly no group difference

    ```{r}
    # #library in TOSTER
    library(TOSTER) # using tost package to test for sample size required to detect no dif between groups

    powerTOSTtwo(alpha=.05, statistical_power=.8, low_eqbound_d=-.5, high_eqbound_d = .5)

    ```

10. Calculate effect size for independent t test where *t = 4.25*.

    ```{r}
    library(tidyverse)
    library(effectsize)
     #get N's for superpower yes/no groups 
      group_by(clean_avengers, superpower) %>%
        summarise(groupsize = n())


    #calculate effect size for t test

    t <- 4.25 # t stat from assignment
    # 
    #code below uses N from data set for superpower yes/no
    n1 <- 780 #group size from summarise n-
    n2 <- 32 # group 2 size """"
    t_to_d(t, df_error = n1+n2-2, paired = FALSE) #indp sample t test convert to cohens d effect size
    cohen.ES(test="t", size ="small")

    ```

Effect size is d = .30, 95% CI \[.016,0.44\]
